{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dabfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# Define the derivative of the sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Define the backpropagation function\n",
    "def backpropagation(inputs, targets, num_hidden_units, learning_rate, num_iterations):\n",
    "    # Initialize the weights of the neural network randomly\n",
    "    input_size = len(inputs[0])\n",
    "    output_size = len(targets[0])\n",
    "#     hidden_weights = [[random.uniform(-1, 1) for j in range(num_hidden_units)] for i in range(input_size)]\n",
    "#     output_weights = [[random.uniform(-1, 1) for j in range(output_size)] for i in range(num_hidden_units)]\n",
    "    hidden_weights = [0.1, 0.6]\n",
    "    output_weights = [0.3, 0.9]\n",
    "    \n",
    "    # Perform backpropagation for the specified number of iterations\n",
    "    for i in range(num_iterations):\n",
    "        # Perform a forward propagation pass through the network\n",
    "        hidden_layer = [sigmoid(sum([inputs[j][k] * hidden_weights[k][h] for k in range(input_size)])) for h in range(num_hidden_units)]\n",
    "        output_layer = [sigmoid(sum([hidden_layer[h] * output_weights[h][j] for h in range(num_hidden_units)])) for j in range(output_size)]\n",
    "        \n",
    "        # Compute the error between the predicted output and the target output\n",
    "        output_error = [targets[j] - output_layer[j] for j in range(output_size)]\n",
    "        hidden_error = [sum([output_error[j] * output_weights[h][j] for j in range(output_size)]) * sigmoid_derivative(hidden_layer[h]) for h in range(num_hidden_units)]\n",
    "        \n",
    "        # Update the weights using the computed gradients and the learning rate\n",
    "        for h in range(num_hidden_units):\n",
    "            for j in range(output_size):\n",
    "                output_weights[h][j] += learning_rate * output_error[j] * hidden_layer[h]\n",
    "        for k in range(input_size):\n",
    "            for h in range(num_hidden_units):\n",
    "                hidden_weights[k][h] += learning_rate * hidden_error[h] * inputs[k][j]\n",
    "    \n",
    "    # Return the learned weights of the neural network\n",
    "    return hidden_weights, output_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd61061d",
   "metadata": {},
   "source": [
    "In this implementation, inputs and targets are the input and target data matrices, num_hidden_units is the number of neurons in the hidden layer, learning_rate is the learning rate used in weight updates, and num_iterations is the number of iterations to perform. The weights are represented as 2D arrays of floating-point numbers, and are randomly initialized between -1 and 1.\n",
    "\n",
    "Note that this implementation is a basic example and may not work well for more complex neural networks or datasets. There are many other factors that can affect the performance of a neural network, such as the choice of activation function, the regularization techniques used, and the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73594ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [0.35, 0.9]\n",
    "targets = [0.5]\n",
    "num_hidden_units = 2\n",
    "learning_rate = 1\n",
    "num_iterations = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "[hidden_weights,output_weights] = backpropagation(inputs, targets, num_hidden_units, learning_rate, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9409e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4a8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac86a12e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dataset.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14620\\2148024017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# Load the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[0;32m   1065\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1068\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    531\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    532\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: dataset.csv not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the derivative of the sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Define the backpropagation function\n",
    "def backpropagation(X, y, num_hidden_units, learning_rate, num_iterations):\n",
    "    # Initialize the weights of the neural network randomly\n",
    "    input_size = X.shape[1]\n",
    "    output_size = y.shape[1]\n",
    "    hidden_weights = np.random.uniform(-1, 1, (input_size, num_hidden_units))\n",
    "    output_weights = np.random.uniform(-1, 1, (num_hidden_units, output_size))\n",
    "    \n",
    "    # Perform backpropagation for the specified number of iterations\n",
    "    for i in range(num_iterations):\n",
    "        # Perform a forward propagation pass through the network\n",
    "        hidden_layer = sigmoid(X @ hidden_weights)\n",
    "        output_layer = sigmoid(hidden_layer @ output_weights)\n",
    "        \n",
    "        # Compute the error between the predicted output and the target output\n",
    "        output_error = y - output_layer\n",
    "        hidden_error = (output_error @ output_weights.T) * sigmoid_derivative(hidden_layer)\n",
    "        \n",
    "        # Update the weights using the computed gradients and the learning rate\n",
    "        output_weights += learning_rate * hidden_layer.T @ output_error\n",
    "        hidden_weights += learning_rate * X.T @ hidden_error\n",
    "    \n",
    "    # Return the learned weights of the neural network\n",
    "    return hidden_weights, output_weights\n",
    "\n",
    "# Load the dataset\n",
    "data = np.loadtxt('backpropagation.csv', delimiter=',')\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1:]\n",
    "\n",
    "# Normalize the input data\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "num_examples = X.shape[0]\n",
    "train_split = int(num_examples * 0.6)\n",
    "val_split = int(num_examples * 0.8)\n",
    "train_X, train_y = X[:train_split], y[:train_split]\n",
    "val_X, val_y = X[train_split:val_split], y[train_split:val_split]\n",
    "test_X, test_y = X[val_split:], y[val_split:]\n",
    "\n",
    "# Train the neural network using backpropagation\n",
    "hidden_weights, output_weights = backpropagation(train_X, train_y, num_hidden_units=4, learning_rate=0.1, num_iterations=1000)\n",
    "\n",
    "# Evaluate the neural network on the validation set\n",
    "hidden_layer = sigmoid(val_X @ hidden_weights)\n",
    "output_layer = sigmoid(hidden_layer @ output_weights)\n",
    "accuracy = np.mean((output_layer > 0.5) == val_y)\n",
    "print('Validation accuracy:', accuracy)\n",
    "\n",
    "# Evaluate the neural network on the test set\n",
    "hidden_layer = sigmoid(test_X @ hidden_weights)\n",
    "output_layer = sigmoid(hidden_layer @ output_weights)\n",
    "accuracy = np.mean((output_layer > 0.5) == test_y)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a109095",
   "metadata": {},
   "source": [
    "In this implementation, X is the input data matrix, y is the target data matrix, num_hidden_units is the number of neurons in the hidden layer, learning_rate is the learning rate used in weight updates, and num_iterations is the number of iterations to perform. The weights are represented as 2D arrays of floating-point numbers, and are randomly initialized between -1 and 1.\n",
    "\n",
    "The implementation also includes code for loading a dataset from a CSV file, normalizing the input data, and splitting the data into training, validation, and test sets. After training the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68565f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
